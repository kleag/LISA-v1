[OS]
save_dir = models/lisa-conll05
load_dir = models/lisa-conll05
save = True
word_file = %(save_dir)s/words.txt
tag_file = %(save_dir)s/tags.txt
rel_file = %(save_dir)s/rels.txt
srl_file = %(save_dir)s/srls.txt
predicate_file = %(save_dir)s/predicates.txt
domain_file = %(save_dir)s/domains.txt
#embed_dir = data/glove
#embed_file = %(embed_dir)s/glove.6B.100d.txt
embed_aux_file = %(embed_dir)s/en.100d.aux.txt
#data_dir = /home/strubell/research/preprocess-conll05/conll05st-release
train_file = %(data_dir)s/train-set.gz.parse.sdeps.combined.bio
valid_file = %(data_dir)s/dev-set.gz.parse.sdeps.combined.bio
test_file = %(data_dir)s/test.wsj.gz.parse.sdeps.combined.bio
gold_dev_props_file = %(data_dir)s/conll2005-dev-gold-props.txt
#gold_test_props_file = %(data_dir)s/conll2005-test-wsj-gold-props.txt
gold_dev_parse_file = %(data_dir)s/conll2005-dev-gold-parse.txt
#gold_test_parse_file = %(data_dir)s/conll2005-test-wsj-gold-parse.txt
transition_statistics = %(data_dir)s/transition_probs.tsv


embed_dir = /home/users/gdechalendar/Projets/Decoder/srl/embeddings
embed_file = %(embed_dir)s/glove.6B.100d.txt
data_dir = /home/users/gdechalendar/Projets/Decoder/srl/preprocess-conll05/conll05st-release
gold_test_props_file = %(data_dir)s/test.wsj-gold-props.txt
gold_test_parse_file = %(data_dir)s/test.wsj-gold-parse.txt


[Dataset]
cased = False
ensure_tree = True
root_label = root
add_to_pretrained = False
min_occur_count = 2
n_bkts = 40
n_valid_bkts = 10
lines_per_buffer = 0
conll = False
conll2012 = True
train_on_nested = True
joint_pos_predicates = True
train_domains = -

[Layers]
n_recur = 12
recur_cell = LSTMCell
recur_bidir = True
forget_bias = 0

[Sizes]
embed_size = 100
predicate_embed_size = 100
recur_size = 400
attn_mlp_size = 500
class_mlp_size = 100
info_mlp_size = 500
predicate_mlp_size = 200
predicate_pred_mlp_size = 200
role_mlp_size = 200

[Functions]
recur_func = tanh
mlp_func = leaky_relu
info_func = leaky_relu

[Regularization]
word_l2_reg = 0
l2_reg = 0

[Dropout]
word_keep_prob = 1.0
tag_keep_prob = 1.0
rel_keep_prob = 1.0
recur_keep_prob = .67
ff_keep_prob = .9
cell_include_prob = 1
hidden_include_prob = 1
mlp_keep_prob = .9
info_keep_prob = .67
attn_dropout = .9
prepost_dropout = .8
relu_dropout = .9

[Learning rate]
learning_rate = 0.04
decay = 1.5
decay_steps = 5000
clip = 1
warmup_steps = 8000

[Radam]
mu = 0.9
nu = 0.98
gamma = 0
chi = 0
epsilon = 1e-12

[Training]
pretrain_iters = 1000
train_iters = 5000000
train_batch_size = 5000
test_batch_size = 5000
validate_every = 100
print_every = 100
save_every = 500
per_process_gpu_memory_fraction = .65
cnn_dim = 1024
cnn_layers = 0
num_heads = 8
head_size = 25
relu_hidden_size = 800
eval_criterion = F1
svd_tree = False
roots_penalty = 0.0
pairs_penalty = 0.0
svd_penalty = 0.0
mask_pairs = False
mask_roots = False
cnn_dim_2d = 128
cnn2d_layers = 0
num_blocks = 1
viterbi_train = False
viterbi_decode = True
parse_update_proportion = 1.0
add_pos_to_input = False
add_predicates_to_input = False
dist_model = transformer
lstm_residual = False
cnn_residual = True
predicate_loss_penalty = 1.0
role_loss_penalty = 1.0
rel_loss_penalty = 0.1
arc_loss_penalty = 1.0
multitask_penalties = parents:1.0
multitask_layers = parents:5
save_attn_weights = True
inject_manual_attn = True
pos_layer = 1
train_pos = False
pos_penalty = 1.0
predicate_str = B-V
parse_layer = 3
predicate_layer = 3
eval_parse = True
eval_srl = True
eval_by_domain = False
num_capsule_heads = 0
gold_attn_at_train = True
eval_single_token_sents = True
hard_attn = False
full_parse = True
sampling_schedule = constant
sample_prob = 1.0
ff_kernel = 1
one_example_per_predicate = False
srl_simple_tagging = False
label_smoothing = 0.1
use_elmo = False
max_test_batch_size = 291
ensure_tree = True

